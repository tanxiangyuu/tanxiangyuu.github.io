<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on tanxiangyu&#39;s log</title>
    <link>https://tanxiangyuu.github.io/posts/test/</link>
    <description>Recent content in LLM on tanxiangyu&#39;s log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 11 Mar 2024 21:15:23 +0800</lastBuildDate>
    <atom:link href="https://tanxiangyuu.github.io/posts/test/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG</title>
      <link>https://tanxiangyuu.github.io/posts/test/rag/</link>
      <pubDate>Mon, 11 Mar 2024 21:15:23 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/test/rag/</guid>
      <description>RAG-Retrieval Augmented Generation 1. RAG介绍 RAG，检索增强生成技术，是一种基于检索的生成模型，它结合了生成模型的灵活性和检索模型的效率。RAG通过将生成模型与检索模型相结合，实现了高效的文本生成。
目的：解决LLM的幻觉情况，加深专业领域深度，更新知识库。
最小RAG的基本结构：
向量化模块，将文档（文本）片段向量化。 文档加载和切分模块，加载文档和切分文档片段。 数据库模块，存放切分好的文档片段及其对应的向量表示 检索模块，根据query检索相应的文档片段。 大模型模块，根据检索出的文档来回答query 生成answer。 RAG的流程 ：
索引：将文档库分割成较短的chunk，并且通过编码器构建向量索引。 检索：根据query和chunks的相似度检索相关文档片段。 生成：通过检索到的文档，作为上下文条件，生成answer。 2. 各个模块的code demo code 待补充。。。
3. 总结 一个最小的RAG包括：
向量化模块 文档加载和切分模块 数据库 检索模块–向量 大模型模块 4. 论文 [1] RAG: Retrieval Augmented Generation for Dense Text-to-Text Pre-training. </description>
    </item>
    <item>
      <title>PyTorch张量基础教程总结</title>
      <link>https://tanxiangyuu.github.io/posts/test/pytorch/</link>
      <pubDate>Tue, 27 Feb 2024 21:28:33 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/test/pytorch/</guid>
      <description>本文是针对PyTorch中的张量（Tensors）的一个基础教程，它详细介绍了张量的定义、特性、以及如何在PyTorch中使用张量进行基本操作。张量是PyTorch中进行科学计算的基础，它们可以视为一个高维数组或矩阵。本教程的主要内容包括：
张量初始化 从数据直接创建张量：可以直接从数据创建张量，PyTorch会自动推断数据类型。 从NumPy数组创建：可以使用torch.from_numpy()从NumPy数组创建张量。 通过已有的张量创建：可以通过已有的张量来创建新的张量。这种方法会默认重用输入张量的属性（如数据类型），除非显式地进行更改。 使用随机或常数值：torch.rand()创建随机初始化的张量，torch.zeros()和torch.ones()分别创建全0或全1的张量。 张量属性 张量属性：张量的属性包括形状（shape）、数据类型（dtype）和存储的设备（device，如CPU或GPU）。 张量操作 索引和切片：可以使用标准的Python索引和切片操作来访问张量的部分。 张量重塑：reshape可以改变张量的形状而不改变其数据。 张量合并：torch.cat可以用来在给定维度上合并张量序列。 张量乘法：介绍了元素乘法（*或torch.mul）和矩阵乘法（@或torch.matmul）。 张量与NumPy之间的转换 张量可以很容易地与NumPy数组相互转换，使用numpy()方法从张量转换为NumPy数组，使用torch.from_numpy()从NumPy数组转换为张量。这两种类型的转换是共享底层内存的，因此修改其中一个会影响另一个。 自动微分 自动微分：PyTorch中的自动微分是通过autograd模块实现的，它提供了张量上所有操作的自动微分。这对于深度学习训练中的梯度计算非常有用。 运行在GPU上 张量可以被移到GPU上：使用.to方法可以将张量移动到任何设备上，这对于加速计算非常重要。 本教程适合初学者，通过详细的示例和解释，帮助读者理解和掌握如何在PyTorch中有效地使用张量进行数据操作和计算。</description>
    </item>
    <item>
      <title>Prompt_engineering</title>
      <link>https://tanxiangyuu.github.io/posts/test/prompt_engineering/</link>
      <pubDate>Tue, 20 Feb 2024 18:48:33 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/test/prompt_engineering/</guid>
      <description>Lilian Weng&amp;rsquo;s blog
提示工程，也被人说为是上下文学习。它的本质上是用来对齐和激活大模型的能力。它需要大量的实验和启发式方法。
她提到，迭代的prompt 和 外部工具的使用 没有那么容易被接受。
Basic Prompting Zero-Shot 就是向LLM简单的提问，向人类交流一样。
Few-shot 少样本提示包括完整的输入和输出示例，以便大模型理解问题，一般具有更加优秀的回答，能够发挥大模型的能力。但是加入示例会消耗一部分token。
prompt的格式选择、训练样本、训练样本的顺序都会对结果造成很大的影响。
有研究调查说明几个有趣的现象：1. 训练数据的label如果分布不均衡，会极大的影响模型能力。2. 最近偏差现象，模型可能会返回训练的最后的几个重复标签，最后训练标签可能权重较大。3. 大模型更加倾向产生常见的token。
Tips for Example Selection 样例选择tips：
选择一些语义上相似的样例。在embedding层使用k-nn聚类。 为了选择多样的回答，可以使用有向图，通过相邻节点选择数来打分，如果相邻节点选择的多，则打分低，选择几率下降。节点连接通过节点间的embedding cosine相似度判断。 多次采样试验中找出分歧或熵较大的示例。然后对这些示例进行注释，以用于少量提示。 Tips for Example Ordering 选择示例多样性，并且随机排列 上下文示例排列不同，结果不同。增大模型规模或者包含更多样例不能消除这种差距。 Instruction Prompting few-shot会花费token，比价昂贵。直接给出指令形式，可能比较经济。understand and follow。be aligned with human intention。
注意：1. 需要描述任务非常仔细。specific and precise 具体而精准。
避免说不要做，而说要做。 解释受众对象。 Self-Consistency Sampling Chain-of-Thought (CoT) 按步骤，短句。解决复杂问题。
Types of CoT prompts 主要有两种cot：
few-shot cot。示例：高质量推理链。cot包含在示例中，数量：4-8. zero-shot cot。 Let&amp;rsquo;s think step by step. Tips and Extensions sefl-consistency sampling 是在decoder层采样多个答案，并且最终经过投票选择最终答案。 prompt具有较高的推理复杂性可以获得更好的性能。cot分隔推理步骤时，使用换行符的效果最好。 使用复杂示例可以提高解决复杂问题的能力，但对简单问题表现不好。 few-shot，示例：使用Question: &amp;amp; Answer: 效果会更好。 在prompt中包含解释的作用可能为小到中等，非事实性的解释会造成错误的答案。 Automatic Prompt Design Augmented Language Models Retrieval Programming Language External APIs Citation Useful Resources References </description>
    </item>
    <item>
      <title>prompt engineering</title>
      <link>https://tanxiangyuu.github.io/posts/test/test/</link>
      <pubDate>Mon, 22 Jan 2024 00:05:03 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/test/test/</guid>
      <description>111111 22222 333333
+++
+++</description>
    </item>
  </channel>
</rss>
