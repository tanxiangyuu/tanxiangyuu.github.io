<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>paper on tanxiangyu&#39;s log</title>
    <link>https://tanxiangyuu.github.io/posts/paper_read/</link>
    <description>Recent content in paper on tanxiangyu&#39;s log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Wed, 17 Jul 2024 22:33:00 +0800</lastBuildDate>
    <atom:link href="https://tanxiangyuu.github.io/posts/paper_read/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>CLINICALGPT: LARGE LANGUAGE MODELS FINETUNED WITH DIVERSE MEDICAL DATA AND COMPREHENSIVE EVALUATION</title>
      <link>https://tanxiangyuu.github.io/posts/paper_read/cinicalgpt/</link>
      <pubDate>Wed, 17 Jul 2024 22:33:00 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/paper_read/cinicalgpt/</guid>
      <description>研究目标 该研究设计和实现了一个能实现多项任务和应用的医学大模型，ClinicalGPT。通过在训练过程中引入多种真实世界数据（如医疗记录、领域特定知识以及多轮对话咨询等）的方式，使其更好地应对多个临床任务。此外，作者还提出了一种全面的评估框架，包括医学知识问答、医学考试、患者咨询以及对电子病历进行诊断分析等多个方面。&#xA;实际问题：&#xA;传统的自然语言处理方法往往需要手动设计特征或规则来进行分类或回答问题，这种方法不仅费时费力，而且难以适应不同场景的需求。而大规模语言模型可以通过无监督学习的方式自动学习到大量的语言规律和语义信息，因此具有更好的泛化能力和适应性。然而，大模型在医疗领域的实际使用中具有局限性。这些模型产生的结果往往与事实不符、逻辑不一致、不连贯，例如引用不存在的文章。它们缺乏真实世界的推理技能和基础，导致了通用和含糊的回复。具体而言，ChatGPT 在医学背景下缺乏深度和洞察力，这可能是由于其基于奖励的训练所使用的排列模型，该模型生成的答案过于笼统，缺乏医学专业知识。&#xA;因此，该研究提出的知识图谱模板化技术和奖励模型可以帮助语言模型更好地理解和应对医学领域中的挑战，从而实现更高效的任务完成。&#xA;是否是新问题：&#xA;虽然在医疗大模型所面临的挑战并非全新，但本研究采用的方法&amp;ndash;开发像 ClinicalGPT 这样的专用模型并针对医疗任务对其进行评估&amp;ndash;却是新颖的。本研究试图直接解决这些已知问题，重点是提高模型在医疗应用中的性能。&#xA;对产业发展的重要意义：&#xA;这项研究对医疗行业的意义在于，它有可能打破特定任务的范式，实现人工智能在医疗保健领域的多功能应用&#xA;新思路与方法 思路&#xA;该研究使用了多种医疗数据集进行模型训练和评估，包括cMedQA2、cMedQA-KG、MD-EHR、MEDQA-MCMLE和MedDialog等。其中：&#xA;cMedQA2是一个包含12万条问题和22.6万条答案的中文医学问答数据集； cMedQA-KG是基于知识图谱构建的医学问答数据集，包含了丰富的医学实体及其关系； MEDQA-MCMLE是基于中国医学考试题库构建的数据集，用于评估临床推理能力； MedDialog是一个由在线平台收集的多轮医学对话数据集，可以模拟医生与患者之间的交互过程； MD-EHR则是一个来自多个大型医院的电子病历数据集，涵盖了各种疾病类型。 为了增强语言模型在特定领域的应用效果，该研究采用了知识图谱模板化技术将知识图谱中的实体和关系转化为适合于指令微调的文本对形式，并利用监督微调的方式进一步优化模型性能。&#xA;此外，该研究还引入了一种奖励模型来为强化学习提供反馈信号，以提高模型生成高质量且有用的输出的概率。&#xA;解决方案关键&#xA;多样的训练数据集 通过知识图谱模板化技术将知识图谱中的实体和关系转化为文本对的形式，可以更好地利用这些结构化的信息来指导模型的学习过程。 同时，奖励模型可以为强化学习提供有效的反馈信号，从而帮助模型生成更加准确和有用的回答。 知识图谱模板化技术如下表所示：&#xA;Prompt Response {疾病}和哪些疾病有关联？ {疾病}可能与{疾病}有关联。 {疾病}可能与其他哪些疾病有关？ {疾病}可能与{疾病}有关联。 {疾病}有哪些常见症状？ {疾病}的常见症状包括{临床表现}。 患有{疾病}的患者可能出现哪些症状？ {疾病}患者可能出现如{临床表现}等症状。 {疾病}的典型临床表现是什么？ {疾病}的典型临床表现为{临床表现}。 患有{疾病}的患者在临床上通常表现为哪些症状？ 患有{疾病}的患者在临床上通常表现为{临床表现}。 诊断{疾病}需要进行哪些检查？ 诊断{疾病}需要进行如{医学检验项目}等检查。 如何检查以确定患有{疾病}？ 确定患有{疾病}需要进行{医学检验项目}等检查。 {药物}主要用于治疗哪些疾病？ {药物}主要用于治疗{疾病}等疾病。 {药物}的适应症是什么？ {药物}的适应症为治疗{疾病}。 如何治疗{疾病}？ 治疗{疾病}的方法包括{医疗程序}。 {疾病}的常见治疗方法有哪些？ {疾病}的常见治疗方法包括{医疗程序}。 {疾病}会引起哪些并发症？ {疾病}会引起{疾病}等并发症。 患有{疾病}的患者可能出现哪些并发症？ 患有{疾病}的患者可能出现{疾病}等并发症。 {药物}与哪些药物存在相互作用？ {药物}与{药物}存在相互作用。 使用{药物}时需要注意哪些药物相互作用？ 使用{药物}时需注意与{药物}的相互作用。 {药物}主要用于治疗哪些症状？ {药物}主要用于治疗{临床表现}等症状。 {药物}的主要治疗作用是什么？ {药物}的主要治疗作用为治疗{临床表现}。 实验设计 本文涉及了以下四个方面的实验：&#xA;医疗对话实验：作者采用了BLEU、ROUGE和GLEU三个评价指标来评估模型生成的对话质量。实验结果表明，ClinicalGPT在所有ROUGE指标上表现优秀，在BLEU-1和大部分ROUGE指标上也表现出色。 医学考试实验：作者选择了MEDQA-MCMLE数据集中的几个类别进行评估，包括医学伦理、呼吸系统、消化系统等。实验结果显示，ClinicalGPT在各个类别中均表现出色，超过了其他LLMs的平均准确率。 诊断实验：作者使用MD-EHR测试集对模型的诊断能力进行了评估。实验结果表明，ClinicalGPT在各个疾病组别中都表现出色，尤其是在消化系统和泌尿系统方面表现最佳。 医学问答实验：作者使用cMedQA2数据集对模型的问答能力进行了评估。实验结果表明，ClinicalGPT在与BLOOM-7B、LLAMA-7B和ChatGLM-6B的比较中表现最好，尤其在与BLOOM-7B和LLAMA-7B的比较中胜出较多。 总的来说，本文的实验结果表明，ClinicalGPT在医疗领域具有出色的应用潜力，特别是在理解和生成医疗对话、医学检查和诊断等方面。然而，在某些特定领域，如妇科和血液系统，可能需要进一步改进。</description>
    </item>
  </channel>
</rss>
