<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on tanxiangyu&#39;s log</title>
    <link>https://tanxiangyuu.github.io/posts/llm/</link>
    <description>Recent content in LLM on tanxiangyu&#39;s log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Fri, 19 Jul 2024 20:09:33 +0800</lastBuildDate>
    <atom:link href="https://tanxiangyuu.github.io/posts/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>医疗文本大模型发展</title>
      <link>https://tanxiangyuu.github.io/posts/llm/%E5%8C%BB%E7%96%97%E6%96%87%E6%9C%AC%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95/</link>
      <pubDate>Fri, 19 Jul 2024 20:09:33 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/llm/%E5%8C%BB%E7%96%97%E6%96%87%E6%9C%AC%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8F%91%E5%B1%95/</guid>
      <description>联仁健康-如何用大模型实现电子病历数据后治理 医学临床数据治理的难点： 不同医院、科室甚至医生的记录风格和用词可能不同 文本信息之间可能存在复杂的关联性和依赖性 同一个描述可能在不同上下文中有不同的含义。 一方面，病历信息的语义环境复杂且结构细碎，呈现异构性和难互通特征，使得数据的完整性、一致性和准确性都难以保证；另一方面，由于标准化认知和遵循不足，医学术语标准化程度不高，导致大量信息资料无法检索，统计结果缺乏普遍性和客观性。&#xA;电子病历数据的规模化、复杂化、多样性、动态性、非标化都是医学临床数据治理的难点。&#xA;针对电子病历数据，联仁健康引入大模型技术，从自然语言结构化，医学术语标准化，数据质量规范化三个方面，降低成本，落实规范，稳定质量。 大模型结构化电子病历文本 第一步对大段文本进行信息提取，包括从入院记录、出院小结、手术记录、病程记录等提取医生需要的临床指标数据。 为了缓解幻觉，采用了多种干预策略： 模型侧使用对齐调整策略，多种提示词优化入参 基于业务逻辑对输出结果进行校验 利用大模型标准医学术语 为了满足医学术语标准化，用医学词汇表和标准化组织的术语和定义，如医学主题词汇（MeSH)、国际疾病分类 (ICD)、国家医保和国家药监发布的药品、诊疗项目、耗材目录等，保证医学数据的标准，使得更加利于统计分析。&#xA;大模型本身在计算资源不足的情况下不适用术语标准化，但可以利用其总结和摘要能力，让其输出和医生表达方式一致的回答，再将输出给联仁自研的术语标准化算法，可以得到更加精准的医学术语归一化结果。&#xA;通常，术语标准化采用的技术方案框架为：多路召唤+精排&#xA;联仁使用的方案是：实体识别+向量编码+快速检索，并用模型量化加速技术，适配不同业务场景。&#xA;例如：椎间盘突出-&amp;gt;椎间盘突出症，焦虑抑郁状态-&amp;gt;焦虑性神经症。&#xA;构建标准化字典（如疾病编码 ICD-10 以及药品 ACT 编码等），将不规范的规范&#xA;数据处理，标准化部分可以看看，主要是搞质控的流程&#xA;森亿智能大模型医疗应用 能够根据患者的信息，跟随医生思路自动灵活扩写病历，包括病情描述、鉴别诊断、治疗方案等信息，边写边生成，无需选择病历模板即可完成病历生成。包括不同角色（交班、汇报、出院）多种角度和方式总结生成病历摘要、治疗建议，出院小结。&#xA;懂医生思维，智能扩写文本，提质增效。例如医生提供”主诉“，根据信息自动生成”起病情况表述“，当医生补充肿块边缘清晰”这一描述信息后，系统自动补全了“肿块质地、活动性&amp;quot;等同类伴随症状的描述。 多样化总结病历摘要，根据不同临床应用场景，以多种方式对文书进行总结。 智能生成出院小结，将手术记录的手术经过，概括写进出院小结的诊疗经过。 通过诊疗经过，生成出院记录。&#xA;阮彤：大模型给电子病历互联互通带来的变革 — 从结构互通到语义互通 不同医疗机构之间的电子病历互联互通，可以相互处理。&#xA;大模型用于电子病历的数据治理 大模型用于电子病历的数据治理&#xA;电子病历数据来自 EMR 数据库，基于电子病历提取慢病患者的关键信息，如患病时长、症状时长、治疗方式。&#xA;EMR&#xA;大量字段/变量未标化 含有大量非结构化数据 常存在矛盾数据 RCD&#xA;尽可能实现字段/变量标准化 核心/关键文本信息结构化 包含人口学特征（基础信息）、暴露、结局等信息 数据治理通常包含： 异常数据处理（缺失、矛盾） 关键信息提取 标准化（手术、诊断、器械、科室） 问题： 重要信息未提取&#xA;如一诉六史中，患者出现症状的时间，既往患病，既往用过哪些药等，在病历中未结构化。 关键信息命名多样化&#xA;各个医院对于同个诊断/手术，可能有不同的描述。 3. 病历质量参差不齐 电子病历关键信息提取 电子病历重要信息包含在“一诉六史”中，以既往史为例，从既往史中抽取14个类型的实体及其之间的关系。 实体类型：疫苗名称, 手术名称, 时长, 疾病名称, 治疗方式, 过敏源, 传染病名称, 否定词, 输血史, 时间, 原因, 外伤部位, 治疗结果, 输血原因 ；关系类型：时长, 治疗方式, 有关, 否定词, 时间, 原因, 治疗结果, 输血原因。</description>
    </item>
    <item>
      <title>RAG</title>
      <link>https://tanxiangyuu.github.io/posts/llm/rag/</link>
      <pubDate>Mon, 11 Mar 2024 21:15:23 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/llm/rag/</guid>
      <description>RAG-Retrieval Augmented Generation 1. RAG介绍 RAG，检索增强生成技术，是一种基于检索的生成模型，它结合了生成模型的灵活性和检索模型的效率。RAG通过将生成模型与检索模型相结合，实现了高效的文本生成。&#xA;目的：解决LLM的幻觉情况，加深专业领域深度，更新知识库。&#xA;最小RAG的基本结构：&#xA;向量化模块，将文档（文本）片段向量化。 文档加载和切分模块，加载文档和切分文档片段。 数据库模块，存放切分好的文档片段及其对应的向量表示 检索模块，根据query检索相应的文档片段。 大模型模块，根据检索出的文档来回答query 生成answer。 RAG的流程 ：&#xA;索引：将文档库分割成较短的chunk，并且通过编码器构建向量索引。 检索：根据query和chunks的相似度检索相关文档片段。 生成：通过检索到的文档，作为上下文条件，生成answer。 2. 各个模块的code demo code 待补充。。。&#xA;3. 总结 一个最小的RAG包括：&#xA;向量化模块 文档加载和切分模块 数据库 检索模块–向量 大模型模块 4. 论文 [1] RAG: Retrieval Augmented Generation for Dense Text-to-Text Pre-training. </description>
    </item>
    <item>
      <title>PyTorch张量基础教程总结</title>
      <link>https://tanxiangyuu.github.io/posts/llm/pytorch/</link>
      <pubDate>Tue, 27 Feb 2024 21:28:33 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/llm/pytorch/</guid>
      <description>本文是针对PyTorch中的张量（Tensors）的一个基础教程，它详细介绍了张量的定义、特性、以及如何在PyTorch中使用张量进行基本操作。张量是PyTorch中进行科学计算的基础，它们可以视为一个高维数组或矩阵。本教程的主要内容包括：&#xA;张量初始化 从数据直接创建张量：可以直接从数据创建张量，PyTorch会自动推断数据类型。 从NumPy数组创建：可以使用torch.from_numpy()从NumPy数组创建张量。 通过已有的张量创建：可以通过已有的张量来创建新的张量。这种方法会默认重用输入张量的属性（如数据类型），除非显式地进行更改。 使用随机或常数值：torch.rand()创建随机初始化的张量，torch.zeros()和torch.ones()分别创建全0或全1的张量。 张量属性 张量属性：张量的属性包括形状（shape）、数据类型（dtype）和存储的设备（device，如CPU或GPU）。 张量操作 索引和切片：可以使用标准的Python索引和切片操作来访问张量的部分。 张量重塑：reshape可以改变张量的形状而不改变其数据。 张量合并：torch.cat可以用来在给定维度上合并张量序列。 张量乘法：介绍了元素乘法（*或torch.mul）和矩阵乘法（@或torch.matmul）。 张量与NumPy之间的转换 张量可以很容易地与NumPy数组相互转换，使用numpy()方法从张量转换为NumPy数组，使用torch.from_numpy()从NumPy数组转换为张量。这两种类型的转换是共享底层内存的，因此修改其中一个会影响另一个。 自动微分 自动微分：PyTorch中的自动微分是通过autograd模块实现的，它提供了张量上所有操作的自动微分。这对于深度学习训练中的梯度计算非常有用。 运行在GPU上 张量可以被移到GPU上：使用.to方法可以将张量移动到任何设备上，这对于加速计算非常重要。 本教程适合初学者，通过详细的示例和解释，帮助读者理解和掌握如何在PyTorch中有效地使用张量进行数据操作和计算。</description>
    </item>
    <item>
      <title>Prompt_engineering</title>
      <link>https://tanxiangyuu.github.io/posts/llm/prompt_engineering/</link>
      <pubDate>Tue, 20 Feb 2024 18:48:33 +0800</pubDate>
      <guid>https://tanxiangyuu.github.io/posts/llm/prompt_engineering/</guid>
      <description>Lilian Weng&amp;rsquo;s blog&#xA;提示工程，也被人说为是上下文学习。它的本质上是用来对齐和激活大模型的能力。它需要大量的实验和启发式方法。&#xA;她提到，迭代的prompt 和 外部工具的使用 没有那么容易被接受。&#xA;Basic Prompting Zero-Shot 就是向LLM简单的提问，向人类交流一样。&#xA;Few-shot 少样本提示包括完整的输入和输出示例，以便大模型理解问题，一般具有更加优秀的回答，能够发挥大模型的能力。但是加入示例会消耗一部分token。&#xA;prompt的格式选择、训练样本、训练样本的顺序都会对结果造成很大的影响。&#xA;有研究调查说明几个有趣的现象：1. 训练数据的label如果分布不均衡，会极大的影响模型能力。2. 最近偏差现象，模型可能会返回训练的最后的几个重复标签，最后训练标签可能权重较大。3. 大模型更加倾向产生常见的token。&#xA;Tips for Example Selection 样例选择tips：&#xA;选择一些语义上相似的样例。在embedding层使用k-nn聚类。 为了选择多样的回答，可以使用有向图，通过相邻节点选择数来打分，如果相邻节点选择的多，则打分低，选择几率下降。节点连接通过节点间的embedding cosine相似度判断。 多次采样试验中找出分歧或熵较大的示例。然后对这些示例进行注释，以用于少量提示。 Tips for Example Ordering 选择示例多样性，并且随机排列 上下文示例排列不同，结果不同。增大模型规模或者包含更多样例不能消除这种差距。 Instruction Prompting few-shot会花费token，比价昂贵。直接给出指令形式，可能比较经济。understand and follow。be aligned with human intention。&#xA;注意：1. 需要描述任务非常仔细。specific and precise 具体而精准。&#xA;避免说不要做，而说要做。 解释受众对象。 Self-Consistency Sampling Chain-of-Thought (CoT) 按步骤，短句。解决复杂问题。&#xA;Types of CoT prompts 主要有两种cot：&#xA;few-shot cot。示例：高质量推理链。cot包含在示例中，数量：4-8. zero-shot cot。 Let&amp;rsquo;s think step by step. Tips and Extensions sefl-consistency sampling 是在decoder层采样多个答案，并且最终经过投票选择最终答案。 prompt具有较高的推理复杂性可以获得更好的性能。cot分隔推理步骤时，使用换行符的效果最好。 使用复杂示例可以提高解决复杂问题的能力，但对简单问题表现不好。 few-shot，示例：使用Question: &amp;amp; Answer: 效果会更好。 在prompt中包含解释的作用可能为小到中等，非事实性的解释会造成错误的答案。 Automatic Prompt Design Augmented Language Models Retrieval Programming Language External APIs Citation Useful Resources References </description>
    </item>
  </channel>
</rss>
