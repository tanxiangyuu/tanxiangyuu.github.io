[{"content":"FRP 内网穿透介绍 互联网上两个不同的主机进行通信首先需要知道对方IP。根据IP协议，只有分配了公网IP的设备才能在互联网上通信和传输数据。而中国人口/设备众多，分配到的IPv4资源又少，因此绝大部分情况是通过路由器/交换机转换公网IP后才上网。 位于路由器/交换机后的设备一般是内网设备，分配的IP地址以 192.168/172.16/10.0 开头，属于内网IP。要让内网设备对外提供服务，就需要进行内网穿透。\nfrp介绍 frp 是一个开源、简洁易用、高性能的内网穿透和反向代理软件，支持 tcp, udp, http, https等协议。 frp 项目官网是 GitHub - fatedier/frp，中文官方文档地址：frp/README_zh.md。除了安装过程，中文文档对使用过程已经介绍的非常详细，如遇到问题，建议先查看官方文档。 frp工作原理为：\n服务端运行，监听一个主端口，等待客户端的连接； 客户端连接到服务端的主端口，同时告诉服务端要监听的端口和转发类型； 服务端fork新的进程监听客户端指定的端口； 外网用户连接到客户端指定的端口，服务端通过和客户端的连接将数据转发到客户端； 客户端进程再将数据转发到本地服务，从而实现内网对外暴露服务的能力。 frp内网穿透教程 部署frp服务端（外网机器） 在frp下载界面，下载 frp，注意根据机器类型选择版本，这里因为我的客户端有人已经装了 frp_0.33.0_linux_amd64.tar.gz，所以在服务端也下载这个版本。 解压安装包：tar -zxvf frp_0.33.0_linux_amd64.tar.gz 进入解压目录：cd frp_0.33.0_linux_amd64，编辑 frps.ini文件，编辑完之后删除注释！！！ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [common] # frp监听的端口，默认是7000，可以改成其他的 bind_port = 7000 # 授权码，请改成更复杂的 token = 12345678 # frp管理后台端口，请按自己需求更改 dashboard_port = 7500 # frp管理后台用户名和密码，请改成自己的 dashboard_user = admin dashboard_pwd = admin enable_prometheus = true # frp日志配置 log_file = /var/log/frps.log log_level = info log_max_days = 3 设置 frp 服务和开机自启动服务。注意以下 bash 代码需要在进入 frp 文件目录之后完成。 1 2 3 4 5 6 mkdir -p /etc/frp cp frps.ini /etc/frp cp frps /usr/bin cp systemd/frps.service /usr/lib/systemd/system/ systemctl enable frps systemctl start frps 确保监听端口：如 7000，和管理后台端口：如 7500，被服务器放开。 如没有放开，在 centos 系统下，防火墙放行端口： 1 2 3 4 5 # 添加监听端口 firewall-cmd --permanent --add-port=7000/tcp # 添加管理后台端口 firewall-cmd --permanent --add-port=7500/tcp firewall-cmd --reload ubuntu：ufw 设置防火墙。\n浏览器打开“http://服务器IP:后台管理端口” ，输入用户名和密码可以查看连接状态： 配置 frp 客户端（内网服务器），并且适配多个服务端 下载frp下载页面，我这边内网服务器上已经有人下载了 33 版本。 解压缩，进入文件夹内 编辑frpc.ini文件，按照需求转发，因为内网服务器上有人装了 frp 了，所以 frpc.ini文件他已经编辑过了，而一个frpc.ini文件只能设置一个服务端，和多个客户端隧道，这时候不能动人家的文件。只能自己新添加一个frpc1.ini文件，设置好之后添加新的服务。 frpc1.ini文件配置： 1 2 3 4 5 6 7 8 9 10 11 12 [common] server_addr = 服务器ip #设置的端口 server_port = 7000 token = 12345678 #配置客户端ssh服务 [ssh1] # ssh1 服务名，每个服务名字必须唯一，也不能和其他frpc.ini文件里的服务名冲突 type = tcp local_ip = 127.0.0.1 local_port = 22 #内网服务器ssh服务端口，可以设置为其他端口，但请保证其他端口开通了ssh连接权限 remote_port = 8080 #自定义的远程服务器端口，也就是以后通过这个端口进行ssh连接，好像一个伪装一样。 防火墙放行端口 设置 frp 服务，和开机自启动服务。 正常情况下，应该新添加一个服务 **frpc1.service**，为每个 frp 示例创建一个新的独立服务单元，但是我的服务器上，并没有激活 frpc.service 服务，原本用户应该是用nohup直接挂载了 frpc.ini 文件。所以我直接修改了 frpc.service 文件。 需要将frpc.service中的 service 下面重新启动 frpc.ini 文件改为 frpc1.ini文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 [Unit] Description=Frp Client Service After=network.target [Service] Type=simple User=nobody Restart=on-failure RestartSec=5s ExecStart=/usr/bin/frpc -c /etc/frp/frpc.ini # 改为frpc1.ini ExecReload=/usr/bin/frpc reload -c /etc/frp/frpc.ini # 改为frpc1.ini [Install] WantedBy=multi-user.target 1 2 3 4 5 6 mkdir -p /etc/frp cp frpc1.ini /etc/frp cp frpc /usr/bin cp systemd/frpc.service /usr/lib/systemd/system/ systemctl enable frpc systemctl start frpc 以上命令代码需要在sudo模式下执行。\n登录frp管理后台，观察客户端是否已经连上来。 使用 ssh 命令连接客户端 ssh usr@x.x.x.x -p yyyy\n1. **usr：客户端用户名** 2. x.x.x.x: 服务端 ip 3. yyyy：remote_port 所指端口。 ","permalink":"https://tanxiangyuu.github.io/posts/linux/frp/","summary":"FRP 内网穿透介绍 互联网上两个不同的主机进行通信首先需要知道对方IP。根据IP协议，只有分配了公网IP的设备才能在互联网上通信和传输数据。而中国人口/设备众多，分配到的IPv4资源又少，因此绝大部分情况是通过路由器/交换机转换公网IP后才上网。 位于路由器/交换机后的设备一般是内网设备，分配的IP地址以 192.168/172.16/10.0 开头，属于内网IP。要让内网设备对外提供服务，就需要进行内网穿透。\nfrp介绍 frp 是一个开源、简洁易用、高性能的内网穿透和反向代理软件，支持 tcp, udp, http, https等协议。 frp 项目官网是 GitHub - fatedier/frp，中文官方文档地址：frp/README_zh.md。除了安装过程，中文文档对使用过程已经介绍的非常详细，如遇到问题，建议先查看官方文档。 frp工作原理为：\n服务端运行，监听一个主端口，等待客户端的连接； 客户端连接到服务端的主端口，同时告诉服务端要监听的端口和转发类型； 服务端fork新的进程监听客户端指定的端口； 外网用户连接到客户端指定的端口，服务端通过和客户端的连接将数据转发到客户端； 客户端进程再将数据转发到本地服务，从而实现内网对外暴露服务的能力。 frp内网穿透教程 部署frp服务端（外网机器） 在frp下载界面，下载 frp，注意根据机器类型选择版本，这里因为我的客户端有人已经装了 frp_0.33.0_linux_amd64.tar.gz，所以在服务端也下载这个版本。 解压安装包：tar -zxvf frp_0.33.0_linux_amd64.tar.gz 进入解压目录：cd frp_0.33.0_linux_amd64，编辑 frps.ini文件，编辑完之后删除注释！！！ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [common] # frp监听的端口，默认是7000，可以改成其他的 bind_port = 7000 # 授权码，请改成更复杂的 token = 12345678 # frp管理后台端口，请按自己需求更改 dashboard_port = 7500 # frp管理后台用户名和密码，请改成自己的 dashboard_user = admin dashboard_pwd = admin enable_prometheus = true # frp日志配置 log_file = /var/log/frps.","title":"Frp"},{"content":"对于堆来说，有几个重要的点，虽然简单，但是需要理解，才能理解堆\n完全二叉树 堆是一个完全二叉树 可以分成，大顶堆和小顶堆 大顶堆：父节点大于等于子节点 小顶堆：父节点小于等于子节点 堆的存储：数组形式\u0026ndash;利用完全二叉树的性质。 ","permalink":"https://tanxiangyuu.github.io/posts/%E7%AE%97%E6%B3%95/%E5%A0%86%E6%8E%92%E5%BA%8F/","summary":"对于堆来说，有几个重要的点，虽然简单，但是需要理解，才能理解堆\n完全二叉树 堆是一个完全二叉树 可以分成，大顶堆和小顶堆 大顶堆：父节点大于等于子节点 小顶堆：父节点小于等于子节点 堆的存储：数组形式\u0026ndash;利用完全二叉树的性质。 ","title":"堆排序"},{"content":"题目：假设有一组无序的数字，找到其中排名第 k 位的数字。\n快排 快速排序是一种优秀的排序算法。\nC++ STL 的 sort，使用的就是“快速排序 + 插入排序 + 堆排序”的方式。\n快排的核心 找准基准值的位置\n通过的是partition操作，将数组分为两部分，小于基准值的放在左边，大于基准值的放在右边。\n然后通过递归，对两边继续进行partition操作。\n问题\n求排名为k的元素，并不需要对整个数组进行排序。 时间复杂度不稳定，最坏的情况会达到O(n^2)。 快速选择排序 针对第一个问题：使用快速选择排序方法解决。在不对数据整体进行排序的前提下，快速找到排名第 k 位的元素，而且时间复杂度还能优化到 O(n)。\n快速选择的核心 当需要快速找到一个元素 X，并且使得小于 X 的元素数量是 k-1 个时，那 X 就是要查找的排名第 k 位的元素了。\n没有必要对整个数组进行排序。\n依旧使用partition操作进行实现。 在partition操作中，将基准值排名ind和 k 进行比较。\n如果 ind 正好等于 k，那说明当前的基准值，就是要找的排名第 k 位的元素； 如果 ind 大于 k，说明排名第 k 位的元素在基准值的前面。接下来，要解决的问题就是，在基准值的前面查找排名第 k 位的元素； 如果 ind 小于 k ，就说明排名第 k 位的元素在基准值的后面，并且，当前包括基准值在内的 ind 个元素，都是小于基准值的元素。那么，问题就转化成了，在基准值的后面查找排名第 k - ind 位的元素。 三种快排的优化 针对第二个问题，稳定系统运行时间。\n三种方法 优化1：单边递归优化 在快排的实现中，使用的是双边递归。如代码：\n1 2 quick_sort(arr, l, x - 1); // 对左半边排序 quick_sort(arr, x + 1 , r); // 对右半边排序 从程序的运行时间来考虑的话，每次函数调用，都会消耗掉一部分运行时间。那只要可以减少函数调用的次数，其实就可以加快一点程序运行的速度。\n单边递归：代码：\n1 2 3 4 5 6 7 8 9 10 11 12 void quick_sort(int *arr, int l, int r) { while (l \u0026lt; r) { // 进行一轮 partition 操作 // 获得基准值的位置 int ind = partition(arr, l, r); // 右侧正常调用递归函数 quick_sort(arr, ind + 1, r); // 用本层处理左侧的排序 r = ind - 1; } return ; } 优化2：三数取中优化-基准值选取优化 基准值选取不合理，会导致算法效率的降低。只有当基准值每次都能将排序区间中的数据平分时，时间复杂度才是最好情况下的 O(nlogn)。\n所谓三点取中法，就是每一轮取排序区间的头、尾和中间元素这三个值，然后把它们排序以后的中间值作为本轮的基准值。\n优化3：partition 操作优化 核心思想：头指针找小值，尾指针找大值，然后交换。免去填空过程。\n补充 在运用快速选择算法以寻找排名第 k 位置的元素时，实际上，一旦我们借助该算法确定了第 k 位元素的值，将这个值与它之前的元素值累加起来，即可得到前 k 位元素的所有值。换言之，快速选择算法不仅能有效解决寻找单个第 k 位元素的问题，还能进一步应用于解决求解前 k 个小或前 k 个大元素等更为广泛的 Top-K 问题。\n","permalink":"https://tanxiangyuu.github.io/posts/%E7%AE%97%E6%B3%95/%E5%BF%AB%E9%80%9F%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F/","summary":"题目：假设有一组无序的数字，找到其中排名第 k 位的数字。\n快排 快速排序是一种优秀的排序算法。\nC++ STL 的 sort，使用的就是“快速排序 + 插入排序 + 堆排序”的方式。\n快排的核心 找准基准值的位置\n通过的是partition操作，将数组分为两部分，小于基准值的放在左边，大于基准值的放在右边。\n然后通过递归，对两边继续进行partition操作。\n问题\n求排名为k的元素，并不需要对整个数组进行排序。 时间复杂度不稳定，最坏的情况会达到O(n^2)。 快速选择排序 针对第一个问题：使用快速选择排序方法解决。在不对数据整体进行排序的前提下，快速找到排名第 k 位的元素，而且时间复杂度还能优化到 O(n)。\n快速选择的核心 当需要快速找到一个元素 X，并且使得小于 X 的元素数量是 k-1 个时，那 X 就是要查找的排名第 k 位的元素了。\n没有必要对整个数组进行排序。\n依旧使用partition操作进行实现。 在partition操作中，将基准值排名ind和 k 进行比较。\n如果 ind 正好等于 k，那说明当前的基准值，就是要找的排名第 k 位的元素； 如果 ind 大于 k，说明排名第 k 位的元素在基准值的前面。接下来，要解决的问题就是，在基准值的前面查找排名第 k 位的元素； 如果 ind 小于 k ，就说明排名第 k 位的元素在基准值的后面，并且，当前包括基准值在内的 ind 个元素，都是小于基准值的元素。那么，问题就转化成了，在基准值的后面查找排名第 k - ind 位的元素。 三种快排的优化 针对第二个问题，稳定系统运行时间。","title":"快速选择排序"},{"content":"RAG-Retrieval Augmented Generation 1. RAG介绍 RAG，检索增强生成技术，是一种基于检索的生成模型，它结合了生成模型的灵活性和检索模型的效率。RAG通过将生成模型与检索模型相结合，实现了高效的文本生成。\n目的：解决LLM的幻觉情况，加深专业领域深度，更新知识库。\n最小RAG的基本结构：\n向量化模块，将文档（文本）片段向量化。 文档加载和切分模块，加载文档和切分文档片段。 数据库模块，存放切分好的文档片段及其对应的向量表示 检索模块，根据query检索相应的文档片段。 大模型模块，根据检索出的文档来回答query 生成answer。 RAG的流程 ：\n索引：将文档库分割成较短的chunk，并且通过编码器构建向量索引。 检索：根据query和chunks的相似度检索相关文档片段。 生成：通过检索到的文档，作为上下文条件，生成answer。 2. 各个模块的code demo code 待补充。。。\n3. 总结 一个最小的RAG包括：\n向量化模块 文档加载和切分模块 数据库 检索模块–向量 大模型模块 4. 论文 [1] RAG: Retrieval Augmented Generation for Dense Text-to-Text Pre-training. ","permalink":"https://tanxiangyuu.github.io/posts/test/rag/","summary":"RAG-Retrieval Augmented Generation 1. RAG介绍 RAG，检索增强生成技术，是一种基于检索的生成模型，它结合了生成模型的灵活性和检索模型的效率。RAG通过将生成模型与检索模型相结合，实现了高效的文本生成。\n目的：解决LLM的幻觉情况，加深专业领域深度，更新知识库。\n最小RAG的基本结构：\n向量化模块，将文档（文本）片段向量化。 文档加载和切分模块，加载文档和切分文档片段。 数据库模块，存放切分好的文档片段及其对应的向量表示 检索模块，根据query检索相应的文档片段。 大模型模块，根据检索出的文档来回答query 生成answer。 RAG的流程 ：\n索引：将文档库分割成较短的chunk，并且通过编码器构建向量索引。 检索：根据query和chunks的相似度检索相关文档片段。 生成：通过检索到的文档，作为上下文条件，生成answer。 2. 各个模块的code demo code 待补充。。。\n3. 总结 一个最小的RAG包括：\n向量化模块 文档加载和切分模块 数据库 检索模块–向量 大模型模块 4. 论文 [1] RAG: Retrieval Augmented Generation for Dense Text-to-Text Pre-training. ","title":"RAG"},{"content":"本文是针对PyTorch中的张量（Tensors）的一个基础教程，它详细介绍了张量的定义、特性、以及如何在PyTorch中使用张量进行基本操作。张量是PyTorch中进行科学计算的基础，它们可以视为一个高维数组或矩阵。本教程的主要内容包括：\n张量初始化 从数据直接创建张量：可以直接从数据创建张量，PyTorch会自动推断数据类型。 从NumPy数组创建：可以使用torch.from_numpy()从NumPy数组创建张量。 通过已有的张量创建：可以通过已有的张量来创建新的张量。这种方法会默认重用输入张量的属性（如数据类型），除非显式地进行更改。 使用随机或常数值：torch.rand()创建随机初始化的张量，torch.zeros()和torch.ones()分别创建全0或全1的张量。 张量属性 张量属性：张量的属性包括形状（shape）、数据类型（dtype）和存储的设备（device，如CPU或GPU）。 张量操作 索引和切片：可以使用标准的Python索引和切片操作来访问张量的部分。 张量重塑：reshape可以改变张量的形状而不改变其数据。 张量合并：torch.cat可以用来在给定维度上合并张量序列。 张量乘法：介绍了元素乘法（*或torch.mul）和矩阵乘法（@或torch.matmul）。 张量与NumPy之间的转换 张量可以很容易地与NumPy数组相互转换，使用numpy()方法从张量转换为NumPy数组，使用torch.from_numpy()从NumPy数组转换为张量。这两种类型的转换是共享底层内存的，因此修改其中一个会影响另一个。 自动微分 自动微分：PyTorch中的自动微分是通过autograd模块实现的，它提供了张量上所有操作的自动微分。这对于深度学习训练中的梯度计算非常有用。 运行在GPU上 张量可以被移到GPU上：使用.to方法可以将张量移动到任何设备上，这对于加速计算非常重要。 本教程适合初学者，通过详细的示例和解释，帮助读者理解和掌握如何在PyTorch中有效地使用张量进行数据操作和计算。\n","permalink":"https://tanxiangyuu.github.io/posts/test/pytorch/","summary":"本文是针对PyTorch中的张量（Tensors）的一个基础教程，它详细介绍了张量的定义、特性、以及如何在PyTorch中使用张量进行基本操作。张量是PyTorch中进行科学计算的基础，它们可以视为一个高维数组或矩阵。本教程的主要内容包括：\n张量初始化 从数据直接创建张量：可以直接从数据创建张量，PyTorch会自动推断数据类型。 从NumPy数组创建：可以使用torch.from_numpy()从NumPy数组创建张量。 通过已有的张量创建：可以通过已有的张量来创建新的张量。这种方法会默认重用输入张量的属性（如数据类型），除非显式地进行更改。 使用随机或常数值：torch.rand()创建随机初始化的张量，torch.zeros()和torch.ones()分别创建全0或全1的张量。 张量属性 张量属性：张量的属性包括形状（shape）、数据类型（dtype）和存储的设备（device，如CPU或GPU）。 张量操作 索引和切片：可以使用标准的Python索引和切片操作来访问张量的部分。 张量重塑：reshape可以改变张量的形状而不改变其数据。 张量合并：torch.cat可以用来在给定维度上合并张量序列。 张量乘法：介绍了元素乘法（*或torch.mul）和矩阵乘法（@或torch.matmul）。 张量与NumPy之间的转换 张量可以很容易地与NumPy数组相互转换，使用numpy()方法从张量转换为NumPy数组，使用torch.from_numpy()从NumPy数组转换为张量。这两种类型的转换是共享底层内存的，因此修改其中一个会影响另一个。 自动微分 自动微分：PyTorch中的自动微分是通过autograd模块实现的，它提供了张量上所有操作的自动微分。这对于深度学习训练中的梯度计算非常有用。 运行在GPU上 张量可以被移到GPU上：使用.to方法可以将张量移动到任何设备上，这对于加速计算非常重要。 本教程适合初学者，通过详细的示例和解释，帮助读者理解和掌握如何在PyTorch中有效地使用张量进行数据操作和计算。","title":"PyTorch张量基础教程总结"},{"content":"原文链接\n引言 尊重与期待：黑客欣赏高质量问题，对好问题持积极态度，但对不假思索或懒惰提问者有所抵触。 提问前的准备工作 自行寻找答案 搜索论坛帖子 使用搜索引擎查询 阅读手册与常见问题解答(FAQ) 自行尝试和测试 向身边专家咨询 如是程序员，阅读源代码 展示前期努力：在提问时，告知你已经尝试过的解决途径，证明你不是一个坐享其成者。 提问技巧 选择合适的提问场所：避免在不相关的论坛提问，查找并选用专门针对你问题的主题论坛或邮件列表。 利用Stack Overflow和Stack Exchange：在提问前先搜索，然后在对应主题的Stack Exchange网站上提问。 邮件列表与IRC：参加项目邮件列表，若有必要，可在开发者邮件列表提问，前提是你已经尝试过用户列表。 编写有效的标题： 标题示例：目标——差异式描述 示例：X.org 6.8.1鼠标指针在MV1005显卡芯片组下的变形问题 方便回复：不要请求直接回复到个人邮箱，而是使用恰当的论坛或邮件列表提问，并确保标题能准确反映问题内容。 清晰表述： 使用正确、清晰、准确的语言，避免拼写、语法错误。 尊重非母语使用者，但力求表达清晰，必要时声明语言障碍。 便于阅读的格式： 使用纯文本格式，避免HTML和特殊格式。 不要发送封闭格式的文档，如Word或Excel文件。 在论坛中适度使用表情符号和格式，保持专业简洁。 问题描述详尽： 描述问题的具体表现。 提供环境信息，如操作系统、应用版本等。 描述已经进行的研究与诊断步骤。 提供可能导致问题变化的背景信息。 提供重现问题的简明步骤。 精炼问题：提供简明扼要且具有针对性的信息，尽量缩小问题范围。 谨慎声称发现Bug： 在确定是Bug之前，先假设可能自身操作不当。 提供详尽的重现步骤及可能的补丁或回归测试证据。 低声下气无助于解决问题 避免以过分谦卑或模糊的方式提出问题，应清晰表述背景及问题细节，不必自我贬低。明确问题的具体症状而非主观猜测，以便他人准确判断和诊断。 提供精确的技术信息 当提问关于技术问题时，务必提供详尽的硬件配置、软件环境及错误现象等信息，如编译错误的例子所示，确保对方能看到与你相同的现象，而非仅听信个人揣测。 遵循问题发生的时间顺序 记录问题出现前的操作流程，按时间顺序详细描述，包括系统的反应和出现问题的具体环节。如有必要，提供调试日志和相关设置，确保信息具有针对性和实用性。 聚焦问题实质而非操作过程 提问时首先阐明你的最终目标，而非纠结于某一无效步骤。例如，当询问颜色选择器获取RGB值时，应说明实际需要达成的任务，以便得到更有效的解决方案。 鼓励公开交流 避免请求私下回复，提倡在公共平台讨论问题，以便更多人参与、纠正错误，并为解答者带来社区认可。只有在特殊情况下，如预期收到大量重复回复时，可提议私下整合信息后回馈至公共平台。 清晰简洁地表述需求 明确告知需要何种形式的帮助，限制所需投入的时间和精力，使专家更容易给出有针对性的回答。简化问题表述，比如求教参考资料来源优于直接要求解释概念。 提供最小化复现代码 当涉及编程问题时，附上精简且能够复现问题的代码片段，明确指出期望结果和实际结果之间的差异。创建最精简的测试用例有助于他人快速定位问题，从而提高获得有效回复的可能性。 对待家庭作业的态度 对于疑似家庭作业性质的问题，黑客社群鼓励自行解决以积累经验。可以请求提示，但不应索要完整答案。在适当场合如用户论坛中提问时，表明你已尽力但仍需指导，或许能得到有益的提示。 去除无意义提问以提升问题质量 避免使用无助于解决问题的结尾疑问句，如\u0026quot;有人能帮我吗？\u0026quot; 不明确的问题加上这类问句反而显多余，易遭黑客社区反感 尽量减少\u0026quot;是/否\u0026quot;型提问，除非期望得到确切的二元答复 慎用“紧急”标签以获取有效关注 标注“紧急”往往适得其反，可能导致问题被忽视或删除 在非专业场合高调标榜紧急可能因垃圾信息过滤而失效 特殊情况下的紧急提及须礼貌且基于共同兴趣点 礼仪助力沟通，提升获得解答的可能性 表达感谢，如使用“请”和“谢谢您的关注”，展示对他人力气的认可 礼貌虽非首要，却有益于问题得到关注，尤其在连续提问情境下 先致谢后再次感谢回复者的具体帮助，避免误解 问题解决后的跟进与分享 解决问题后及时告知并感谢参与者 使用“已解决”等标记更新原话题标题，方便他人查阅 简洁概述问题解决方法及原因，提及关键协助者 提供简洁的调试摘要或指出避免问题的途径 正确反馈问题解决状态有助于满足解答者成就感 考虑编写文档或添加FAQ，防止他人重复遇到相同问题 如何解读答案 RTFM 和 STFW：遭遇经典回应的意义与应对 当收到RTFM或STFW回复时，这意味着你应该查阅相关手册或自行上网搜索。 这类回答表明信息易于获取，自行搜索能促进学习，而非直接给予答案。 收到此类回复应视为对方已在某种程度上提供了关注，对此表示感谢。 面对困惑时的正确求解姿态 若无法理解回复，尝试自行解决，参考手册、FAQ、网络资源或请教他人。 提出疑问时展现自主探索过程，如举例询问具体的细节而非基础概念。 应对无礼回应与黑客文化 黑客圈内的直率交流可能被误认为无礼，遇此情况保持冷静。 如确实遭受冒犯，社群内其他成员可能会介入纠正不当行为。 对于真正的冒犯者，有力反击可被接受，但新手需谨慎判断，避免陷入无谓争执。 黑客文化中的某些特质可能源于独特的社交习惯，不必过分解读。 Jeff Bigler 的观点：应对策略 Jeff Bigler 关于“社交过滤器”的观察可作为理解和适应黑客社群互动方式的参考。 如何避免扮演失败者 面对批评与纠正 接受并忍受在黑客社区中因失误而受到的公开批评，这是社区标准得以维持的方式。不应期待所有意见都通过私人途径传达，避免将建设性批评视为个人攻击。 处理挑衅行为 遇到无端指责时，保持冷静，避免陷入口水战。黑客指出错误是出于关心社区和个人成长，不应为此抱怨或要求特殊对待。 学会区分口水战与实质性回复 多数口水战无需理会，确认其中是否包含对问题实质的解答或有价值的建议。 不该问的问题及其典型回应 寻找资源路径 利用搜索引擎寻找所需程序或资源，基本查询能力应当具备。 操作方法问题 提问过于宽泛，未能明确问题焦点，建议先自行研究Y问题的本质。 配置问题 自行阅读手册（RTFM），自行查找答案。 文件转换问题 自行尝试并验证可行性。 无效的程序/设置问题表述 提供具体问题详情，避免空泛陈述。 针对Windows的问题 优先考虑更换操作系统或在适当场合提问，如涉及与开源软件交互问题。 质疑系统工具有效性 确保问题归因准确，提供详细证据。 安装Linux或其他操作系统问题 寻求本地用户群组的帮助，提供具体故障细节。 非法活动请求 黑客不会支持非法行为，此类问题不会得到回答。 好问题与蠢问题的区别 展示搜索努力 聪明的问题表明提问者已经尽力搜索但仍未解决问题，寻求进一步指引。 尊重他人时间 避免责备他人或表现出傲慢态度，详细描述问题背景和已尝试的解决方案。 得不到回答时的对策 保持耐心 问题可能因多种原因暂时未得到回答，重复张贴问题非明智之举。 寻求其他援助渠道 加入用户群组或寻求商业支持，理解免费技术支持的局限性。 如何更好地回答问题 友好态度 保持礼貌和善，理解提问者可能承受的压力。 私下回复初犯者 对真诚的新手私下指导，避免公开羞辱。 不确定时明确表态 避免给出错误答案，鼓励提问者提供更多细节。 避免误导性玩笑 不要给出可能破坏提问者设置的玩笑性建议。 引导提问者细化问题 通过反问引导提问者提供更多细节，促进双方学习。 给出高质量答案 避免给出权宜之计，推荐更好的工具或重新定义问题。 正面回答并分享技巧 在回答时强调解决问题的方法，而非单纯提供结果。 推动社区进步 从问题中总结经验教训，改进文档和常见问题解答，以便未来参考。 ","permalink":"https://tanxiangyuu.github.io/posts/test/%E6%8F%90%E9%97%AE%E7%9A%84%E6%99%BA%E6%85%A7/","summary":"原文链接\n引言 尊重与期待：黑客欣赏高质量问题，对好问题持积极态度，但对不假思索或懒惰提问者有所抵触。 提问前的准备工作 自行寻找答案 搜索论坛帖子 使用搜索引擎查询 阅读手册与常见问题解答(FAQ) 自行尝试和测试 向身边专家咨询 如是程序员，阅读源代码 展示前期努力：在提问时，告知你已经尝试过的解决途径，证明你不是一个坐享其成者。 提问技巧 选择合适的提问场所：避免在不相关的论坛提问，查找并选用专门针对你问题的主题论坛或邮件列表。 利用Stack Overflow和Stack Exchange：在提问前先搜索，然后在对应主题的Stack Exchange网站上提问。 邮件列表与IRC：参加项目邮件列表，若有必要，可在开发者邮件列表提问，前提是你已经尝试过用户列表。 编写有效的标题： 标题示例：目标——差异式描述 示例：X.org 6.8.1鼠标指针在MV1005显卡芯片组下的变形问题 方便回复：不要请求直接回复到个人邮箱，而是使用恰当的论坛或邮件列表提问，并确保标题能准确反映问题内容。 清晰表述： 使用正确、清晰、准确的语言，避免拼写、语法错误。 尊重非母语使用者，但力求表达清晰，必要时声明语言障碍。 便于阅读的格式： 使用纯文本格式，避免HTML和特殊格式。 不要发送封闭格式的文档，如Word或Excel文件。 在论坛中适度使用表情符号和格式，保持专业简洁。 问题描述详尽： 描述问题的具体表现。 提供环境信息，如操作系统、应用版本等。 描述已经进行的研究与诊断步骤。 提供可能导致问题变化的背景信息。 提供重现问题的简明步骤。 精炼问题：提供简明扼要且具有针对性的信息，尽量缩小问题范围。 谨慎声称发现Bug： 在确定是Bug之前，先假设可能自身操作不当。 提供详尽的重现步骤及可能的补丁或回归测试证据。 低声下气无助于解决问题 避免以过分谦卑或模糊的方式提出问题，应清晰表述背景及问题细节，不必自我贬低。明确问题的具体症状而非主观猜测，以便他人准确判断和诊断。 提供精确的技术信息 当提问关于技术问题时，务必提供详尽的硬件配置、软件环境及错误现象等信息，如编译错误的例子所示，确保对方能看到与你相同的现象，而非仅听信个人揣测。 遵循问题发生的时间顺序 记录问题出现前的操作流程，按时间顺序详细描述，包括系统的反应和出现问题的具体环节。如有必要，提供调试日志和相关设置，确保信息具有针对性和实用性。 聚焦问题实质而非操作过程 提问时首先阐明你的最终目标，而非纠结于某一无效步骤。例如，当询问颜色选择器获取RGB值时，应说明实际需要达成的任务，以便得到更有效的解决方案。 鼓励公开交流 避免请求私下回复，提倡在公共平台讨论问题，以便更多人参与、纠正错误，并为解答者带来社区认可。只有在特殊情况下，如预期收到大量重复回复时，可提议私下整合信息后回馈至公共平台。 清晰简洁地表述需求 明确告知需要何种形式的帮助，限制所需投入的时间和精力，使专家更容易给出有针对性的回答。简化问题表述，比如求教参考资料来源优于直接要求解释概念。 提供最小化复现代码 当涉及编程问题时，附上精简且能够复现问题的代码片段，明确指出期望结果和实际结果之间的差异。创建最精简的测试用例有助于他人快速定位问题，从而提高获得有效回复的可能性。 对待家庭作业的态度 对于疑似家庭作业性质的问题，黑客社群鼓励自行解决以积累经验。可以请求提示，但不应索要完整答案。在适当场合如用户论坛中提问时，表明你已尽力但仍需指导，或许能得到有益的提示。 去除无意义提问以提升问题质量 避免使用无助于解决问题的结尾疑问句，如\u0026quot;有人能帮我吗？\u0026quot; 不明确的问题加上这类问句反而显多余，易遭黑客社区反感 尽量减少\u0026quot;是/否\u0026quot;型提问，除非期望得到确切的二元答复 慎用“紧急”标签以获取有效关注 标注“紧急”往往适得其反，可能导致问题被忽视或删除 在非专业场合高调标榜紧急可能因垃圾信息过滤而失效 特殊情况下的紧急提及须礼貌且基于共同兴趣点 礼仪助力沟通，提升获得解答的可能性 表达感谢，如使用“请”和“谢谢您的关注”，展示对他人力气的认可 礼貌虽非首要，却有益于问题得到关注，尤其在连续提问情境下 先致谢后再次感谢回复者的具体帮助，避免误解 问题解决后的跟进与分享 解决问题后及时告知并感谢参与者 使用“已解决”等标记更新原话题标题，方便他人查阅 简洁概述问题解决方法及原因，提及关键协助者 提供简洁的调试摘要或指出避免问题的途径 正确反馈问题解决状态有助于满足解答者成就感 考虑编写文档或添加FAQ，防止他人重复遇到相同问题 如何解读答案 RTFM 和 STFW：遭遇经典回应的意义与应对 当收到RTFM或STFW回复时，这意味着你应该查阅相关手册或自行上网搜索。 这类回答表明信息易于获取，自行搜索能促进学习，而非直接给予答案。 收到此类回复应视为对方已在某种程度上提供了关注，对此表示感谢。 面对困惑时的正确求解姿态 若无法理解回复，尝试自行解决，参考手册、FAQ、网络资源或请教他人。 提出疑问时展现自主探索过程，如举例询问具体的细节而非基础概念。 应对无礼回应与黑客文化 黑客圈内的直率交流可能被误认为无礼，遇此情况保持冷静。 如确实遭受冒犯，社群内其他成员可能会介入纠正不当行为。 对于真正的冒犯者，有力反击可被接受，但新手需谨慎判断，避免陷入无谓争执。 黑客文化中的某些特质可能源于独特的社交习惯，不必过分解读。 Jeff Bigler 的观点：应对策略 Jeff Bigler 关于“社交过滤器”的观察可作为理解和适应黑客社群互动方式的参考。 如何避免扮演失败者 面对批评与纠正 接受并忍受在黑客社区中因失误而受到的公开批评，这是社区标准得以维持的方式。不应期待所有意见都通过私人途径传达，避免将建设性批评视为个人攻击。 处理挑衅行为 遇到无端指责时，保持冷静，避免陷入口水战。黑客指出错误是出于关心社区和个人成长，不应为此抱怨或要求特殊对待。 学会区分口水战与实质性回复 多数口水战无需理会，确认其中是否包含对问题实质的解答或有价值的建议。 不该问的问题及其典型回应 寻找资源路径 利用搜索引擎寻找所需程序或资源，基本查询能力应当具备。 操作方法问题 提问过于宽泛，未能明确问题焦点，建议先自行研究Y问题的本质。 配置问题 自行阅读手册（RTFM），自行查找答案。 文件转换问题 自行尝试并验证可行性。 无效的程序/设置问题表述 提供具体问题详情，避免空泛陈述。 针对Windows的问题 优先考虑更换操作系统或在适当场合提问，如涉及与开源软件交互问题。 质疑系统工具有效性 确保问题归因准确，提供详细证据。 安装Linux或其他操作系统问题 寻求本地用户群组的帮助，提供具体故障细节。 非法活动请求 黑客不会支持非法行为，此类问题不会得到回答。 好问题与蠢问题的区别 展示搜索努力 聪明的问题表明提问者已经尽力搜索但仍未解决问题，寻求进一步指引。 尊重他人时间 避免责备他人或表现出傲慢态度，详细描述问题背景和已尝试的解决方案。 得不到回答时的对策 保持耐心 问题可能因多种原因暂时未得到回答，重复张贴问题非明智之举。 寻求其他援助渠道 加入用户群组或寻求商业支持，理解免费技术支持的局限性。 如何更好地回答问题 友好态度 保持礼貌和善，理解提问者可能承受的压力。 私下回复初犯者 对真诚的新手私下指导，避免公开羞辱。 不确定时明确表态 避免给出错误答案，鼓励提问者提供更多细节。 避免误导性玩笑 不要给出可能破坏提问者设置的玩笑性建议。 引导提问者细化问题 通过反问引导提问者提供更多细节，促进双方学习。 给出高质量答案 避免给出权宜之计，推荐更好的工具或重新定义问题。 正面回答并分享技巧 在回答时强调解决问题的方法，而非单纯提供结果。 推动社区进步 从问题中总结经验教训，改进文档和常见问题解答，以便未来参考。 ","title":"如何向黑客有效地提问"},{"content":"Lilian Weng\u0026rsquo;s blog\n提示工程，也被人说为是上下文学习。它的本质上是用来对齐和激活大模型的能力。它需要大量的实验和启发式方法。\n她提到，迭代的prompt 和 外部工具的使用 没有那么容易被接受。\nBasic Prompting Zero-Shot 就是向LLM简单的提问，向人类交流一样。\nFew-shot 少样本提示包括完整的输入和输出示例，以便大模型理解问题，一般具有更加优秀的回答，能够发挥大模型的能力。但是加入示例会消耗一部分token。\nprompt的格式选择、训练样本、训练样本的顺序都会对结果造成很大的影响。\n有研究调查说明几个有趣的现象：1. 训练数据的label如果分布不均衡，会极大的影响模型能力。2. 最近偏差现象，模型可能会返回训练的最后的几个重复标签，最后训练标签可能权重较大。3. 大模型更加倾向产生常见的token。\nTips for Example Selection 样例选择tips：\n选择一些语义上相似的样例。在embedding层使用k-nn聚类。 为了选择多样的回答，可以使用有向图，通过相邻节点选择数来打分，如果相邻节点选择的多，则打分低，选择几率下降。节点连接通过节点间的embedding cosine相似度判断。 多次采样试验中找出分歧或熵较大的示例。然后对这些示例进行注释，以用于少量提示。 Tips for Example Ordering 选择示例多样性，并且随机排列 上下文示例排列不同，结果不同。增大模型规模或者包含更多样例不能消除这种差距。 Instruction Prompting few-shot会花费token，比价昂贵。直接给出指令形式，可能比较经济。understand and follow。be aligned with human intention。\n注意：1. 需要描述任务非常仔细。specific and precise 具体而精准。\n避免说不要做，而说要做。 解释受众对象。 Self-Consistency Sampling Chain-of-Thought (CoT) 按步骤，短句。解决复杂问题。\nTypes of CoT prompts 主要有两种cot：\nfew-shot cot。示例：高质量推理链。cot包含在示例中，数量：4-8. zero-shot cot。 Let\u0026rsquo;s think step by step. Tips and Extensions sefl-consistency sampling 是在decoder层采样多个答案，并且最终经过投票选择最终答案。 prompt具有较高的推理复杂性可以获得更好的性能。cot分隔推理步骤时，使用换行符的效果最好。 使用复杂示例可以提高解决复杂问题的能力，但对简单问题表现不好。 few-shot，示例：使用Question: \u0026amp; Answer: 效果会更好。 在prompt中包含解释的作用可能为小到中等，非事实性的解释会造成错误的答案。 Automatic Prompt Design Augmented Language Models Retrieval Programming Language External APIs Citation Useful Resources References ","permalink":"https://tanxiangyuu.github.io/posts/test/prompt_engineering/","summary":"Lilian Weng\u0026rsquo;s blog\n提示工程，也被人说为是上下文学习。它的本质上是用来对齐和激活大模型的能力。它需要大量的实验和启发式方法。\n她提到，迭代的prompt 和 外部工具的使用 没有那么容易被接受。\nBasic Prompting Zero-Shot 就是向LLM简单的提问，向人类交流一样。\nFew-shot 少样本提示包括完整的输入和输出示例，以便大模型理解问题，一般具有更加优秀的回答，能够发挥大模型的能力。但是加入示例会消耗一部分token。\nprompt的格式选择、训练样本、训练样本的顺序都会对结果造成很大的影响。\n有研究调查说明几个有趣的现象：1. 训练数据的label如果分布不均衡，会极大的影响模型能力。2. 最近偏差现象，模型可能会返回训练的最后的几个重复标签，最后训练标签可能权重较大。3. 大模型更加倾向产生常见的token。\nTips for Example Selection 样例选择tips：\n选择一些语义上相似的样例。在embedding层使用k-nn聚类。 为了选择多样的回答，可以使用有向图，通过相邻节点选择数来打分，如果相邻节点选择的多，则打分低，选择几率下降。节点连接通过节点间的embedding cosine相似度判断。 多次采样试验中找出分歧或熵较大的示例。然后对这些示例进行注释，以用于少量提示。 Tips for Example Ordering 选择示例多样性，并且随机排列 上下文示例排列不同，结果不同。增大模型规模或者包含更多样例不能消除这种差距。 Instruction Prompting few-shot会花费token，比价昂贵。直接给出指令形式，可能比较经济。understand and follow。be aligned with human intention。\n注意：1. 需要描述任务非常仔细。specific and precise 具体而精准。\n避免说不要做，而说要做。 解释受众对象。 Self-Consistency Sampling Chain-of-Thought (CoT) 按步骤，短句。解决复杂问题。\nTypes of CoT prompts 主要有两种cot：\nfew-shot cot。示例：高质量推理链。cot包含在示例中，数量：4-8. zero-shot cot。 Let\u0026rsquo;s think step by step. Tips and Extensions sefl-consistency sampling 是在decoder层采样多个答案，并且最终经过投票选择最终答案。 prompt具有较高的推理复杂性可以获得更好的性能。cot分隔推理步骤时，使用换行符的效果最好。 使用复杂示例可以提高解决复杂问题的能力，但对简单问题表现不好。 few-shot，示例：使用Question: \u0026amp; Answer: 效果会更好。 在prompt中包含解释的作用可能为小到中等，非事实性的解释会造成错误的答案。 Automatic Prompt Design Augmented Language Models Retrieval Programming Language External APIs Citation Useful Resources References ","title":"Prompt_engineering"},{"content":"测试直接新建md文件 hugo 新建命令：hugo -F --cleanDestinationDir\n1 hugo -F --cleanDestinationDir hugo 新建文档命令：hugo new dir/name.md\n","permalink":"https://tanxiangyuu.github.io/posts/test/hugo%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95/","summary":"测试直接新建md文件 hugo 新建命令：hugo -F --cleanDestinationDir\n1 hugo -F --cleanDestinationDir hugo 新建文档命令：hugo new dir/name.md","title":"Hugo命令记录"},{"content":"111111 22222 333333\n+++\n+++\n","permalink":"https://tanxiangyuu.github.io/posts/test/test/","summary":"111111 22222 333333\n+++\n+++","title":"prompt engineering"}]